seed: 1
max_seq_len: 1024
device_eval_batch_size: 4
models:
-
  model_name: mpt-example # required for some reason
  model:
    name: fmapi_causal_lm # used for lookup in COMPOSER_MODEL_REGISTRY
    base_url: http://0.0.0.0:8080/v2

  tokenizer:
    name: tiktoken
    kwargs:
      model_name: gpt-3.5-turbo

icl_tasks:
-
  label: bigbench_simple_arithmetic
  dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_simple_arithmetic.jsonl
  num_fewshot: [2] # [10]
  icl_task_type: language_modeling
